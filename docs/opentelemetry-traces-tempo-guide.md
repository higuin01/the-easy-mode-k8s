# ğŸ“Š OpenTelemetry + Grafana Tempo: Guia Completo para Traces

## ğŸ¯ VisÃ£o Geral

Este guia explica como configurar **distributed tracing** usando **OpenTelemetry** e **Grafana Tempo** na sua stack Kubernetes. O objetivo Ã© capturar, processar e visualizar traces de aplicaÃ§Ãµes de forma automÃ¡tica.

### ğŸ”„ Fluxo de Dados (Data Flow)

```
[AplicaÃ§Ã£o Java] 
    â†“ (auto-instrumentaÃ§Ã£o)
[OpenTelemetry Agent] 
    â†“ (OTLP gRPC - porta 4317)
[OpenTelemetry Collector] 
    â†“ (OTLP gRPC - porta 4317)
[Grafana Tempo] 
    â†“ (consulta)
[Grafana Dashboard]
```

---

## ğŸ—ï¸ Arquitetura dos Componentes

### 1. **OpenTelemetry Operator**
- **FunÃ§Ã£o**: Gerencia auto-instrumentaÃ§Ã£o de aplicaÃ§Ãµes
- **Namespace**: `opentelemetry-operator-system`
- **Responsabilidades**:
  - Injeta agents de instrumentaÃ§Ã£o automaticamente
  - Gerencia configuraÃ§Ãµes de instrumentaÃ§Ã£o por linguagem
  - Cria e gerencia OpenTelemetry Collectors

### 2. **OpenTelemetry Collector**
- **FunÃ§Ã£o**: Recebe, processa e exporta telemetria
- **Modo**: DaemonSet (roda em cada nÃ³)
- **Namespace**: `monitoring`
- **Responsabilidades**:
  - Recebe traces via OTLP (portas 4317/4318)
  - Adiciona metadados Kubernetes
  - Envia traces para Grafana Tempo

### 3. **Grafana Tempo**
- **FunÃ§Ã£o**: Armazena e consulta traces distribuÃ­dos
- **Arquitetura**: DistribuÃ­da (distributor, ingester, querier, etc.)
- **Namespace**: `monitoring`
- **Responsabilidades**:
  - Armazena traces de forma eficiente
  - Fornece API de consulta para Grafana
  - Gerencia retenÃ§Ã£o e compactaÃ§Ã£o

---

## ğŸ“ Estrutura de Arquivos e ConfiguraÃ§Ãµes

### ğŸ”§ 1. OpenTelemetry Operator (`/scripts/helm/otel-operator/`)

#### `values.yaml` - ConfiguraÃ§Ã£o do Operator
```yaml
# ConfiguraÃ§Ã£o mÃ­nima do OpenTelemetry Operator
replicaCount: 1

manager:
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
  env:
    ENABLE_WEBHOOKS: "true"  # Habilita auto-instrumentaÃ§Ã£o
    OTEL_RESOURCE_ATTRIBUTES: "service.name=opentelemetry-operator"
```

**ğŸ“ ExplicaÃ§Ã£o**:
- `ENABLE_WEBHOOKS`: Permite que o operator injete instrumentaÃ§Ã£o automaticamente
- Recursos limitados para ambiente de desenvolvimento
- O operator monitora annotations nos pods para decidir quando instrumentar

#### `instrumentation.yaml` - ConfiguraÃ§Ã£o de Auto-instrumentaÃ§Ã£o
```yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: default-instrumentation
  namespace: opentelemetry-operator-system
spec:
  # ğŸ¯ CRÃTICO: Endpoint onde traces serÃ£o enviados
  exporter:
    endpoint: http://otel-collector-collector.monitoring.svc.cluster.local:4317
  
  # Formatos de propagaÃ§Ã£o de contexto
  propagators:
    - tracecontext  # W3C Trace Context (padrÃ£o)
    - baggage       # W3C Baggage
    - b3            # Zipkin B3 (compatibilidade)
  
  # ConfiguraÃ§Ã£o de sampling (25% dos traces)
  sampler:
    type: parentbased_traceidratio
    argument: "0.25"
  
  # ConfiguraÃ§Ãµes por linguagem
  java:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-java:latest
    env:
      - name: OTEL_JAVAAGENT_DEBUG
        value: "false"
      - name: OTEL_INSTRUMENTATION_JDBC_ENABLED
        value: "true"  # Instrumenta queries SQL
      - name: OTEL_INSTRUMENTATION_KAFKA_ENABLED
        value: "true"  # Instrumenta Kafka
```

**ğŸ“ ExplicaÃ§Ã£o**:
- **Endpoint**: Deve apontar para o Collector (porta 4317 = gRPC)
- **Sampling**: 25% reduz overhead, mas mantÃ©m visibilidade
- **Propagators**: Garantem que contexto de trace seja mantido entre serviÃ§os
- **Por linguagem**: Cada linguagem tem configuraÃ§Ãµes especÃ­ficas

#### `opentelemetry-collector.yaml` - ConfiguraÃ§Ã£o do Collector
```yaml
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector
  namespace: monitoring
spec:
  mode: daemonset  # Roda em cada nÃ³ do cluster
  
  config:
    # ğŸ“¥ RECEIVERS: Como receber telemetria
    receivers:
      otlp:  # Protocolo nativo OpenTelemetry
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317  # Para aplicaÃ§Ãµes modernas
          http:
            endpoint: 0.0.0.0:4318  # Para compatibilidade
      
      jaeger:  # Para aplicaÃ§Ãµes legacy
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268

    # ğŸ”„ PROCESSORS: Como processar telemetria
    processors:
      batch:
        timeout: 1s
        send_batch_size: 1024  # Agrupa traces para eficiÃªncia
      
      resource:
        attributes:
          - key: cluster.name
            value: "local-k8s"
            action: insert
          - key: deployment.environment
            value: "development"
            action: insert
      
      k8sattributes:  # Adiciona metadados Kubernetes
        auth_type: "serviceAccount"
        extract:
          metadata:
            - k8s.pod.name
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name

    # ğŸ“¤ EXPORTERS: Para onde enviar telemetria
    exporters:
      otlp/tempo:
        endpoint: http://tempo-distributor.monitoring.svc.cluster.local:4317
        tls:
          insecure: true
      
      debug:  # Para troubleshooting
        verbosity: detailed

    # ğŸ”€ PIPELINES: Fluxo de processamento
    service:
      pipelines:
        traces:
          receivers: [otlp, jaeger]
          processors: [k8sattributes, resource, batch]
          exporters: [otlp/tempo, debug]
```

**ğŸ“ ExplicaÃ§Ã£o**:
- **DaemonSet**: Garante que cada nÃ³ tenha um collector
- **Receivers**: MÃºltiplos protocolos para compatibilidade
- **k8sattributes**: Enriquece traces com informaÃ§Ãµes do Kubernetes
- **Batch processor**: Melhora performance agrupando dados
- **Pipeline**: Define o fluxo completo de processamento

---

### ğŸ¯ 2. Grafana Tempo (`/scripts/helm/tempo/`)

#### `values.yaml` - ConfiguraÃ§Ã£o do Tempo
```yaml
fullnameOverride: tempo

# ğŸ”Œ PROTOCOLOS: Quais formatos aceitar
traces:
  jaeger:
    grpc:
      enabled: true
    thriftHttp:
      enabled: true
  zipkin:
    enabled: true
  otlp:  # ğŸ¯ PRINCIPAL: OpenTelemetry nativo
    http:
      enabled: true
    grpc:
      enabled: true

# ğŸ—ï¸ COMPONENTES DISTRIBUÃDOS
distributor:
  replicas: 1  # Recebe traces
  resources:
    limits:
      cpu: 500m
      memory: 512Mi

ingester:
  replicas: 2  # ğŸš¨ IMPORTANTE: MÃ­nimo 2 para replicaÃ§Ã£o
  resources:
    limits:
      cpu: 500m
      memory: 1Gi
  persistence:
    enabled: true
    size: 10Gi

querier:
  replicas: 1  # Processa consultas
  
queryFrontend:
  replicas: 1  # Interface de consulta

compactor:
  replicas: 1  # Compacta dados antigos

# ğŸ“Š CONFIGURAÃ‡Ã•ES GLOBAIS
global_overrides:
  ingestion_rate_limit_bytes: 20000000
  ingestion_burst_size_bytes: 30000000
  max_traces_per_user: 10000
  ingestion_rate_strategy: local      # Para single-tenant
  max_global_traces_per_user: 0       # Sem limite global

# ğŸ’¾ ARMAZENAMENTO
storage:
  trace:
    backend: local  # Para desenvolvimento
    local:
      path: /var/tempo/traces
    wal:
      path: /var/tempo/wal
```

**ğŸ“ ExplicaÃ§Ã£o**:
- **Ingester replicas: 2**: Tempo exige mÃ­nimo 2 rÃ©plicas para replicaÃ§Ã£o
- **Protocolos mÃºltiplos**: Aceita OTLP, Jaeger e Zipkin
- **Storage local**: Para desenvolvimento; produÃ§Ã£o usaria S3/GCS
- **Rate limiting**: Protege contra sobrecarga

---

## ğŸš€ Como Usar Auto-instrumentaÃ§Ã£o

### 1. **Instrumentar AplicaÃ§Ã£o Java**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minha-app-java
spec:
  template:
    metadata:
      annotations:
        # ğŸ¯ CHAVE: Esta annotation ativa auto-instrumentaÃ§Ã£o
        instrumentation.opentelemetry.io/inject-java: "opentelemetry-operator-system/default-instrumentation"
    spec:
      containers:
      - name: app
        image: minha-app:latest
        env:
        # ğŸ“ IDENTIFICAÃ‡ÃƒO: Nome do serviÃ§o nos traces
        - name: OTEL_SERVICE_NAME
          value: "minha-app-producao"
        # ğŸ·ï¸ METADADOS: InformaÃ§Ãµes adicionais
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: "service.name=minha-app,service.version=1.2.3,environment=production"
```

### 2. **O que Acontece Automaticamente**

1. **Operator detecta** a annotation
2. **Injeta init container** com Java agent
3. **Configura variÃ¡veis** de ambiente OTEL_*
4. **Agent instrumenta** automaticamente:
   - HTTP requests/responses
   - Database queries (JDBC)
   - Kafka producers/consumers
   - Spring Boot endpoints
   - E muito mais...

### 3. **Outras Linguagens**

```yaml
# Node.js
instrumentation.opentelemetry.io/inject-nodejs: "opentelemetry-operator-system/default-instrumentation"

# Python
instrumentation.opentelemetry.io/inject-python: "opentelemetry-operator-system/default-instrumentation"

# .NET
instrumentation.opentelemetry.io/inject-dotnet: "opentelemetry-operator-system/default-instrumentation"
```

---

## ğŸ” VisualizaÃ§Ã£o no Grafana

### 1. **Configurar Data Source**
- **URL**: `http://tempo-query-frontend.monitoring.svc.cluster.local:3200`
- **Access**: Server (default)

### 2. **Consultar Traces**
```
# Por serviÃ§o
{service.name="minha-app-producao"}

# Por operaÃ§Ã£o
{service.name="minha-app-producao" && name="GET /api/users"}

# Por erro
{service.name="minha-app-producao" && status=error}
```

### 3. **InformaÃ§Ãµes DisponÃ­veis**
- **DuraÃ§Ã£o** de cada operaÃ§Ã£o
- **DependÃªncias** entre serviÃ§os
- **Erros** e stack traces
- **Metadados** Kubernetes
- **CorrelaÃ§Ã£o** com logs e mÃ©tricas

---

## ğŸ› ï¸ Comandos de InstalaÃ§Ã£o

```bash
# 1. Instalar Tempo
./scripts/helm-install.sh tempo

# 2. Instalar OpenTelemetry Operator
./scripts/helm-install.sh otel-operator

# 3. Verificar se estÃ¡ funcionando
kubectl get pods -n monitoring | grep -E "(tempo|otel)"
kubectl get pods -n opentelemetry-operator-system
```

---

## ğŸ”§ Troubleshooting

### âŒ **Problema**: Traces nÃ£o aparecem no Grafana
```bash
# Verificar se collector estÃ¡ recebendo
kubectl logs -l app.kubernetes.io/name=otel-collector-collector -n monitoring | grep -i trace

# Verificar se Tempo estÃ¡ recebendo
kubectl logs -l app.kubernetes.io/name=tempo,app.kubernetes.io/component=distributor -n monitoring
```

### âŒ **Problema**: Auto-instrumentaÃ§Ã£o nÃ£o funciona
```bash
# Verificar se annotation foi aplicada
kubectl describe pod <nome-do-pod> | grep -i instrumentation

# Verificar se init container foi injetado
kubectl get pod <nome-do-pod> -o jsonpath='{.spec.initContainers[*].name}'
```

### âŒ **Problema**: Erro "at least 2 live replicas required"
- **SoluÃ§Ã£o**: Aumentar `ingester.replicas` para 2 no Tempo

---

## ğŸ“ˆ BenefÃ­cios para ProduÃ§Ã£o

1. **Observabilidade Completa**: VÃª exatamente onde tempo Ã© gasto
2. **Debug DistribuÃ­do**: Rastreia requests atravÃ©s de mÃºltiplos serviÃ§os
3. **Performance Insights**: Identifica gargalos automaticamente
4. **Zero Code Changes**: Auto-instrumentaÃ§Ã£o nÃ£o requer mudanÃ§as no cÃ³digo
5. **CorrelaÃ§Ã£o**: Liga traces com logs e mÃ©tricas no Grafana

---

## ğŸ¯ PrÃ³ximos Passos

Agora que traces estÃ£o funcionando, podemos configurar:
1. **Loki** para logs correlacionados
2. **Mimir** para mÃ©tricas de longa duraÃ§Ã£o
3. **Alerting** baseado em traces
4. **Service Map** no Grafana

---

**âœ… Stack de Traces Completa e Funcionando!** ğŸš€